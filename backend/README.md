# 全息拉普拉斯互联网爬虫系统 - 后端服务版

基于全息拉普拉斯互联网图理论的网页爬虫系统，通过浏览器访问本地API服务，而非传统的配置文件方式。

## 系统特点

- **服务器模式**：爬虫以服务形式运行，支持多任务并发执行
- **实时监控**：实时监控任务执行状态与进度
- **灵活配置**：通过网页界面配置，无需编程知识
- **内容清洗**：自动移除广告、导航栏等噪声内容
- **自动分类**：基于内容相似度自动对爬取的网页进行分类
- **阴谋论检测**：基于全息拉普拉斯互联网图理论的网页内容分析

## 系统架构

```
+---------------------+     HTTP请求     +---------------------+
|   浏览器前端界面    | <-------------> |   本地Flask服务器   |
| (HTML/CSS/JS 页面)  |                 | (Python后端服务)    |
+---------------------+                 +---------------------+
                                               |
                                               | 执行爬虫任务
                                               v
                                        +---------------------+
                                        |   爬虫引擎         |
                                        | (WebCrawler 类)    |
                                        +---------------------+
                                               |
                                               | 处理数据
                                               v
                                        +---------------------+
                                        |   数据处理器       |
                                        | (DataProcessor 类) |
                                        +---------------------+
                                               |
                                               | 分析结果
                                               v
                                        +---------------------+
                                        |   阴谋论分析器     |
                                        | (UrbanLegendAnalyzer)|
                                        +---------------------+
                                               |
                                               | 存储结果
                                               v
                                        +---------------------+
                                        |   任务结果存储     |
                                        | (results 目录)     |
                                        +---------------------+
```

## 安装与运行

### 系统要求

- Python 3.7 或更高版本
- 操作系统：Windows/Linux/macOS

### 安装步骤

1. 确保安装了Python环境
2. 克隆或下载本仓库到本地
3. 运行启动脚本：
   - Windows: 双击运行 `start.bat`
   - Linux/macOS: 在终端运行 `./startup.sh`

脚本会自动安装所需的依赖库：
```
requests beautifulsoup4 nltk scikit-learn flask flask-cors
```

### 手动安装

如果自动安装失败，可以手动安装依赖：

```bash
# 安装依赖库
pip install requests beautifulsoup4 nltk scikit-learn flask flask-cors

# 启动服务器
python crawler_server.py
```

## 使用方法

### 启动服务

1. 运行启动脚本 (`start.bat` 或 `startup.sh`)
2. 服务器将在 http://localhost:5000 上运行
3. 在浏览器中打开 `index.html` 文件

### 配置并启动爬虫任务

1. 在URL列表中输入要爬取的网站地址（每行一个）
2. 设置爬取深度（1-3级）和存储格式（TXT或HTML）
3. 设置并发数
4. 点击"运行爬虫"开始执行爬取任务

### 查看任务进度和结果

1. 切换到"任务列表"标签页查看所有任务
2. 点击"查看结果"按钮查看已完成任务的详细内容
3. 切换不同标签页查看爬取内容、分类结果和统计信息

## API接口说明

服务器提供以下API接口：

| 接口路径 | 方法 | 描述 |
|---------|------|------|
| `/api/submit` | POST | 提交爬虫任务 |
| `/api/status/<task_id>` | GET | 获取任务状态 |
| `/api/result/<task_id>` | GET | 获取任务结果 |
| `/api/download/<task_id>` | GET | 下载任务结果文件 |
| `/api/tasks` | GET | 获取所有任务列表 |
| `/api/cancel/<task_id>` | POST | 取消任务 |
| `/api/upload` | POST | 上传配置文件 |
| `/health` | GET | 健康检查 |

## 文件结构

```
├── index.html           # 前端界面
├── styles.css           # 样式文件
├── script.js            # 前端脚本
├── api_client.js        # API客户端
├── crawler_server.py    # 后端服务器
├── crawler.py           # 爬虫实现
├── startup.sh           # Linux/macOS启动脚本
├── start.bat            # Windows启动脚本
├── uploads/             # 上传文件目录
├── results/             # 结果存储目录
└── logs/                # 日志目录
```

## 更新说明

相比原始版本，后端服务版主要改进：

1. **服务器模式**：爬虫作为服务持续运行，支持多任务同时执行
2. **任务管理**：引入任务队列和管理界面
3. **实时状态**：提供任务实时进度和状态监控
4. **API化**：所有功能通过API接口访问，便于集成
5. **统一存储**：任务结果集中存储，易于管理和查询

## 理论基础

本系统基于全息拉普拉斯互联网图理论，是一种新型的互联网动态拓扑模型，它将全息原理与拉普拉斯矩阵分析有机结合，用于描述和解析全球互联网中各节点间复杂的结构关系及动态演变。

该理论提供了以下优势：
- 通过局部信息推断全局网络结构
- 利用谱分析方法进行网络连通性研究
- 采用全息映射确保局部与全局信息的一致性

## 常见问题

**Q: 服务器启动失败怎么办？**  
A: 请检查端口5000是否被占用，可以在启动脚本中修改端口号。

**Q: 爬虫任务一直等待中怎么办？**  
A: 可能是线程池已满，请等待其他任务完成或重启服务器。

**Q: 如何增加爬虫并发数？**  
A: 在配置面板中选择更高的并发选项。但注意过高的并发可能导致被目标网站屏蔽。

## 开发者信息

如有问题或建议，请提交Issue或Pull Request。

## 许可证

MIT 许可证
